{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPdOrEES0cEe"
      },
      "source": [
        "**import necessary packages **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngC7xTv200on",
        "outputId": "58fdd0db-07b1-497a-b36b-1e3ad8fefcf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install langchain -qU\n",
        "!pip install langchain-openai -qU\n",
        "!pip install langchain-google-genai -qU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QYsQMmab1QnW"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import os\n",
        "from google.colab import userdata #this is for the open ai key if it is not used as a secret no need this code line\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdqyUptx1zsO"
      },
      "source": [
        "# initialize language model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TbM0T7Bz19VH"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "#set google api key\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "#initialize the ChatGoogleGenerativeAI model\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0) # Using a valid Gemini model name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsZZ1SmM3tZs"
      },
      "source": [
        "# Initialize prompt Template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3e2-zvD7oc2"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Sv_yoscX32VN"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "#create a prompt template\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"you are an intelligent chatbot. answer the following question.\"),\n",
        "        (\"user\", \"{question}\")\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YfDbb625NIV"
      },
      "source": [
        "# Initialize output parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UMxCsWRX5VHF"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "#create an output parser\n",
        "parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NzJn9u2F5kme"
      },
      "outputs": [],
      "source": [
        "#chain the prompt,LLM,and output parser\n",
        "chain =prompt | llm | parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORYdy3eR51KG",
        "outputId": "bb0e98ea-b143-4419-a778-47f6743bb1d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The capital of France is **Paris**.\n"
          ]
        }
      ],
      "source": [
        "question = \"what is the capital of france?\"\n",
        "response = chain.invoke({\"question\": question})\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrHhlzRTCFF1"
      },
      "source": [
        "# Initialize prompt templatr for dynamic intreaction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Kl0dbv9FAV_V"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "from langchain_core.messages import HumanMessage,AIMessage, SystemMessage\n",
        "\n",
        "#create a prompt template using messagePlaceHolder for the question\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        SystemMessage(content=\"you are an intelligent chatbot. answer the following question.\"),\n",
        "        MessagesPlaceholder(variable_name=\"question\")\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JmQ41ST6BtaG"
      },
      "outputs": [],
      "source": [
        "#chain the prompt,LLM,and output parser\n",
        "chain =prompt | llm | parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGu6yCIWCSZV",
        "outputId": "3c90e394-a1f0-4b57-96fa-f77c84f13929"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hi Kaveen! It's nice to meet you. How can I help you today?\n"
          ]
        }
      ],
      "source": [
        "question = \"hii i am kaveen\"\n",
        "response = chain.invoke({\"question\":[HumanMessage(content=question)]})\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECap9BtYDedt",
        "outputId": "c162c8f4-f9b6-4cc4-ea89-77146b294a4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "As an AI, I don't know who you are in the personal sense. I don't have access to your identity, your memories, your experiences, or your physical presence.\n",
            "\n",
            "\"Who am I?\" is a deeply personal and often philosophical question that only you can truly answer. It can refer to many aspects of your being:\n",
            "\n",
            "*   **Your name and personal details:** (e.g., \"I am [Your Name], a [Your Profession/Role]\").\n",
            "*   **Your personality and character:** (e.g., \"I am kind, curious, and determined\").\n",
            "*   **Your relationships:** (e.g., \"I am a child, a parent, a friend, a colleague\").\n",
            "*   **Your beliefs and values:** (e.g., \"I am someone who believes in justice and compassion\").\n",
            "*   **Your experiences and history:** (e.g., \"I am the sum of everything I've lived through\").\n",
            "*   **Your aspirations and goals:** (e.g., \"I am someone striving to achieve X\").\n",
            "*   **Your unique essence:** The intangible qualities that make you, *you*.\n",
            "\n",
            "If you'd like to explore aspects of identity, self-discovery, or discuss your thoughts on this question, I'm here to listen and engage!\n"
          ]
        }
      ],
      "source": [
        "question = \"who am i\"\n",
        "response = chain.invoke({\"question\":[HumanMessage(content=question)]})\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "novhmxlsaDlz"
      },
      "source": [
        "# chat History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ieAHRInvaQAB"
      },
      "outputs": [],
      "source": [
        "#create a prompt template with a predefined conversation history and a new question placeholder\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        SystemMessage(content=\"you are an intelligent chatbot. answer the following question.\"),\n",
        "        HumanMessage(content=\"My name is kaveen \"),\n",
        "        AIMessage(content=\"Hi Kaveen! It's nice to meet you. How can I help you today? \"),\n",
        "        MessagesPlaceholder(variable_name=\"question\")\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LRBXt8bCbZw6"
      },
      "outputs": [],
      "source": [
        "chain =prompt | llm | parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2aKjjx8bdNR",
        "outputId": "e12099c8-6770-4b9a-e052-9d0c469ae2b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on what you've told me, you are **Kaveen**.\n",
            "\n",
            "As an AI, I only know the information you provide in our conversation. Is there something specific you'd like to know or discuss about yourself?\n"
          ]
        }
      ],
      "source": [
        "question = \"who am i?\"\n",
        "response = chain.invoke({\"question\":[HumanMessage(content=question)]})\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "chatbot-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
